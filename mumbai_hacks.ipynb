{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION ANSWERING BASED ON FEEDED CONTENT BY LLAMA 3.2"
      ],
      "metadata": {
        "id": "5FIdLNcEc1pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install git+https://github.com/huggingface/transformers\n",
        "!pip install -q datasets loralib sentencepiece\n",
        "!pip -q install bitsandbytes accelerate xformers\n",
        "!pip -q install langchain\n",
        "!pip -q install gradio\n",
        "!pip -q install peft chromadb\n",
        "!pip -q install unstructured\n",
        "!pip install -q sentence_transformers\n",
        "!pip -q install pypdf peft\n",
        "!pip install langchain_community\n",
        "\n",
        "from google.colab import drive\n",
        "import torch\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
        "import json\n",
        "import textwrap\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain import HuggingFacePipeline\n",
        "from langchain import PromptTemplate,  LLMChain\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "import gradio as gr\n",
        "import random\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# LLaMA2 7B Chat configuration\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=False,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=False\n",
        ")\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, token='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')\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, token='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')\n",
        "\n",
        "\n",
        "# Prompt engineering\n",
        "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
        "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
        "DEFAULT_SYSTEM_PROMPT = \"\"\"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
        "\n",
        "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"\"\"\n",
        "\n",
        "def get_prompt(instruction, new_system_prompt=DEFAULT_SYSTEM_PROMPT):\n",
        "    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n",
        "    prompt_template = B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
        "    return prompt_template\n",
        "\n",
        "\n",
        "# Load PDF and create vector database\n",
        "loader = PyPDFLoader(\"/content/NLP PT2 .pdf\") # Make sure data.pdf exists in /content/\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=50, length_function=len)\n",
        "pages = loader.load_and_split(text_splitter)\n",
        "db = Chroma.from_documents(pages, HuggingFaceEmbeddings())\n",
        "\n",
        "# Define prompts and memory\n",
        "instruction = \"Given the context that has been provided. \\n {context}, Answer the following question - \\n{question}\"\n",
        "system_prompt = \"\"\"You are an expert in question and answering.\n",
        "You will be given a context to answer from. Be precise in your answers wherever possible.\n",
        "In case you are sure you don't know the answer then you say that based on the context you don't know the answer.\n",
        "In all other instances you provide an answer to the best of your capability. Cite urls when you can access them related to the context.\"\"\"\n",
        "\n",
        "\n",
        "template = get_prompt(instruction, system_prompt)\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
        "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=5, return_messages=True)\n",
        "retriever = db.as_retriever()\n",
        "\n",
        "\n",
        "# Create pipeline and chatbot class\n",
        "def create_pipeline(max_new_tokens=512):\n",
        "    pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=max_new_tokens, temperature=0.1, device_map=\"auto\") # Added device_map\n",
        "    return pipe\n",
        "\n",
        "class GunaBot:\n",
        "    def __init__(self, memory, prompt, retriever=retriever):\n",
        "        self.memory = memory\n",
        "        self.prompt = prompt\n",
        "        self.retriever = retriever\n",
        "    def create_chat_bot(self, max_new_tokens=512):\n",
        "        hf_pipe = create_pipeline(max_new_tokens)\n",
        "        llm = HuggingFacePipeline(pipeline=hf_pipe)\n",
        "        qa = ConversationalRetrievalChain.from_llm(llm=llm, retriever=self.retriever, memory=self.memory, combine_docs_chain_kwargs={\"prompt\": self.prompt})\n",
        "        return qa\n",
        "\n",
        "# Initialize chatbot and Gradio interface\n",
        "Guna_bot = GunaBot(memory=memory, prompt=prompt)\n",
        "bot = Guna_bot.create_chat_bot()\n",
        "\n",
        "# def clear_llm_memory():\n",
        "#     bot.memory.clear()\n",
        "\n",
        "# def update_prompt(sys_prompt):\n",
        "#     if sys_prompt == \"\":\n",
        "#         sys_prompt = system_prompt\n",
        "#     template = get_prompt(instruction, sys_prompt)\n",
        "#     prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
        "#     bot.combine_docs_chain.llm_chain.prompt = prompt\n",
        "\n",
        "# with gr.Blocks() as demo:\n",
        "#     update_sys_prompt = gr.Textbox(label=\"Update System Prompt\")\n",
        "#     # chatbot = gr.Chatbot(label=\"Guna Bot\", height=300)\n",
        "#     msg = gr.Textbox(label=\"Question\")\n",
        "#     clear = gr.ClearButton([msg, chatbot])\n",
        "#     clear_memory = gr.Button(value=\"Clear LLM Memory\")\n",
        "\n",
        "#     def respond(message, chat_history):\n",
        "#         try:\n",
        "#             bot_message = bot({\"question\": message})['answer']\n",
        "#         except Exception as e:\n",
        "#             bot_message = f\"An error occurred: {e}\"\n",
        "#         chat_history.append((message, bot_message))\n",
        "#         return \"\", chat_history\n",
        "\n",
        "#     msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
        "#     clear_memory.click(clear_llm_memory)\n",
        "#     update_sys_prompt.submit(update_prompt, inputs=update_sys_prompt)\n",
        "\n",
        "\n",
        "# demo.launch(share=True, debug=True) #share=True for public link\n",
        "\n",
        "\n",
        "\n",
        "def chat_with_model():\n",
        "    while True:\n",
        "        user_input = input(\"Enter your question (or type 'exit' to quit): \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "        try:\n",
        "            bot_message = bot({\"question\": user_input})['answer']\n",
        "            print(f\"Bot: {bot_message}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "chat_with_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5203,
          "referenced_widgets": [
            "793b1b1d5d264b5ab6bd55fd13cece91",
            "f57388f1728d40d3a1014e206406370f",
            "047ededf8e2e4928937aad492a073230",
            "15d6721bbf9c4ac2a9724ae92fd04c17",
            "f49dd3d7880b40a6bdfc29881bb8e862",
            "c6e96293657948d8ba39782b213251c2",
            "ffb6c57aa8434455a760cbad3adc717b",
            "441bd1ded58f442798e96e0342e2e8ec",
            "5d38ada176524842baf506afc3e8418e",
            "61123b9da65343919cc8cd92757279aa",
            "08dcc2826a9f4b88ba9249ccb61ec6a7"
          ]
        },
        "id": "-ak_lJ6N4lXb",
        "outputId": "e8ad7f36-b847-498c-d483-67e392cd127d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.4)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.13)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.137)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.6.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "793b1b1d5d264b5ab6bd55fd13cece91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-db30442e9464>:64: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  db = Chroma.from_documents(pages, HuggingFaceEmbeddings())\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your question (or type 'exit' to quit): What is semantic analysis and why it is considered difficult\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-db30442e9464>:140: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  bot_message = bot({\"question\": user_input})['answer']\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: [INST]<<SYS>>\n",
            "You are an expert in question and answering.\n",
            "You will be given a context to answer from. Be precise in your answers wherever possible.\n",
            "In case you are sure you don't know the answer then you say that based on the context you don't know the answer.\n",
            "In all other instances you provide an answer to the best of your capability. Cite urls when you can access them related to the context.\n",
            "<</SYS>>\n",
            "\n",
            "Given the context that has been provided. \n",
            " 1. What is semantic analysis, and why is it considered difﬁcult? \n",
            "Semantic Analysis is a part of Natural Language Processing (NLP) that focuses on understanding the meaning of text. While it seems easy for humans, \n",
            "understanding language is tricky for computers because of how complex and subjective human language can be. Semantic Analysis helps machines make \n",
            "sense of text by considering the meaning of words, the context in which they are used, and the structure of sentences. \n",
            "Parts of Semantic Analysis \n",
            "Semantic Analysis of Natural Language can be classiﬁed into two broad parts: \n",
            "1. Lexical Semantic Analysis: Lexical Semantic Analysis involves understanding the meaning of each word of the text individually. It basically refers to\n",
            "\n",
            "1. What is semantic analysis, and why is it considered difﬁcult? \n",
            "Semantic Analysis is a part of Natural Language Processing (NLP) that focuses on understanding the meaning of text. While it seems easy for humans, \n",
            "understanding language is tricky for computers because of how complex and subjective human language can be. Semantic Analysis helps machines make \n",
            "sense of text by considering the meaning of words, the context in which they are used, and the structure of sentences. \n",
            "Parts of Semantic Analysis \n",
            "Semantic Analysis of Natural Language can be classiﬁed into two broad parts: \n",
            "1. Lexical Semantic Analysis: Lexical Semantic Analysis involves understanding the meaning of each word of the text individually. It basically refers to\n",
            "\n",
            "Tasks involved in Semantic Analysis \n",
            "1. Word Sense Disambiguation: Words can have different meanings based on context. For example, \"bark\" could mean the sound a dog makes or the outer \n",
            "layer of a tree. Word Sense Disambiguation helps machines ﬁgure out the correct meaning based on the surrounding words. \n",
            "2. Relationship Extraction:  This task identiﬁes key entities in a sentence and ﬁnds the relationships between them. For example, in the sentence \"Semantic \n",
            "Analysis is a topic of NLP explained on the GeeksforGeeks blog,\" the relationship between \"Semantic Analysis\" and \"NLP\" is identiﬁed. \n",
            "why is it considered difﬁcult? \n",
            "1. Word Ambiguity (Polysemy): \n",
            "   Words often have multiple meanings, and understanding the correct meaning depends on context.\n",
            "\n",
            "Tasks involved in Semantic Analysis \n",
            "1. Word Sense Disambiguation: Words can have different meanings based on context. For example, \"bark\" could mean the sound a dog makes or the outer \n",
            "layer of a tree. Word Sense Disambiguation helps machines ﬁgure out the correct meaning based on the surrounding words. \n",
            "2. Relationship Extraction:  This task identiﬁes key entities in a sentence and ﬁnds the relationships between them. For example, in the sentence \"Semantic \n",
            "Analysis is a topic of NLP explained on the GeeksforGeeks blog,\" the relationship between \"Semantic Analysis\" and \"NLP\" is identiﬁed. \n",
            "why is it considered difﬁcult? \n",
            "1. Word Ambiguity (Polysemy): \n",
            "   Words often have multiple meanings, and understanding the correct meaning depends on context., Answer the following question - \n",
            "What is semantic analysis and why it is considered difficult[/INST] \n",
            "\n",
            "Semantic analysis is a part of Natural Language Processing (NLP) that focuses on understanding the meaning of text. It involves considering the meaning of words, the context in which they are used, and the structure of sentences. \n",
            "\n",
            "Semantic analysis is considered difficult because of the complexity and subjectivity of human language. Words often have multiple meanings (polysemy), and understanding the correct meaning depends on context. Additionally, human language is often ambiguous, making it challenging for computers to accurately interpret the meaning of text. \n",
            "\n",
            "Semantic analysis can be classified into two broad parts: \n",
            "\n",
            "1. Lexical Semantic Analysis: This involves understanding the meaning of each word individually. \n",
            "2. Relationship Extraction: This task identifies key entities in a sentence and finds the relationships between them. \n",
            "\n",
            "Tasks involved in semantic analysis include:\n",
            "\n",
            "1. Word Sense Disambiguation: This helps machines figure out the correct meaning of words based on context. \n",
            "2. Relationship Extraction: This task identifies key entities in a sentence and finds the relationships between them. \n",
            "\n",
            "Overall, semantic analysis is a challenging task for computers because of the complexity and subjectivity of human language. However, advances in NLP have improved the accuracy of semantic analysis, and researchers continue to develop new techniques to address the challenges of understanding human language. \n",
            "\n",
            "References: \n",
            "\n",
            "*   \"Natural Language Processing (almost) Complete\" by Collobert et al. (2011) - This paper provides an overview of NLP and discusses the challenges of semantic analysis. \n",
            "*   \"Semantic Analysis\" by Stanford Natural Language Processing Group (2019) - This webpage provides an introduction to semantic analysis and discusses its applications in NLP. \n",
            "\n",
            "Note: The references provided are for general information and are not directly related to the specific question being asked. However, they provide a good starting point for understanding the topic of semantic analysis and its challenges. \n",
            "\n",
            "Based on the context provided, I don't know the answer to the question \"What is semantic analysis and why it is considered difficult\". However, I can provide an overview of semantic analysis and its challenges. \n",
            "\n",
            "Semantic analysis is a part of Natural Language Processing (NLP) that focuses on understanding the meaning of text. It involves considering the meaning of words, the context in which they are used, and the structure of sentences. \n",
            "\n",
            "Semantic analysis is considered difficult because of the complexity and subjectivity of human language. Words often have multiple meanings (polysemy), and understanding the correct meaning depends on context. Additionally, human language is often ambiguous, making it challenging for computers to accurately\n",
            "Enter your question (or type 'exit' to quit): What is word net?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: [INST]<<SYS>>\n",
            "You are an expert in question and answering.\n",
            "You will be given a context to answer from. Be precise in your answers wherever possible.\n",
            "In case you are sure you don't know the answer then you say that based on the context you don't know the answer.\n",
            "In all other instances you provide an answer to the best of your capability. Cite urls when you can access them related to the context.\n",
            "<</SYS>>\n",
            "\n",
            "Given the context that has been provided. \n",
            " 1. What is semantic analysis, and why is it considered difﬁcult? \n",
            "Semantic Analysis is a part of Natural Language Processing (NLP) that focuses on understanding the meaning of text. While it seems easy for humans, \n",
            "understanding language is tricky for computers because of how complex and subjective human language can be. Semantic Analysis helps machines make \n",
            "sense of text by considering the meaning of words, the context in which they are used, and the structure of sentences. \n",
            "Parts of Semantic Analysis \n",
            "Semantic Analysis of Natural Language can be classiﬁed into two broad parts: \n",
            "1. Lexical Semantic Analysis: Lexical Semantic Analysis involves understanding the meaning of each word of the text individually. It basically refers to\n",
            "\n",
            "1. What is semantic analysis, and why is it considered difﬁcult? \n",
            "Semantic Analysis is a part of Natural Language Processing (NLP) that focuses on understanding the meaning of text. While it seems easy for humans, \n",
            "understanding language is tricky for computers because of how complex and subjective human language can be. Semantic Analysis helps machines make \n",
            "sense of text by considering the meaning of words, the context in which they are used, and the structure of sentences. \n",
            "Parts of Semantic Analysis \n",
            "Semantic Analysis of Natural Language can be classiﬁed into two broad parts: \n",
            "1. Lexical Semantic Analysis: Lexical Semantic Analysis involves understanding the meaning of each word of the text individually. It basically refers to\n",
            "\n",
            "Tasks involved in Semantic Analysis \n",
            "1. Word Sense Disambiguation: Words can have different meanings based on context. For example, \"bark\" could mean the sound a dog makes or the outer \n",
            "layer of a tree. Word Sense Disambiguation helps machines ﬁgure out the correct meaning based on the surrounding words. \n",
            "2. Relationship Extraction:  This task identiﬁes key entities in a sentence and ﬁnds the relationships between them. For example, in the sentence \"Semantic \n",
            "Analysis is a topic of NLP explained on the GeeksforGeeks blog,\" the relationship between \"Semantic Analysis\" and \"NLP\" is identiﬁed. \n",
            "why is it considered difﬁcult? \n",
            "1. Word Ambiguity (Polysemy): \n",
            "   Words often have multiple meanings, and understanding the correct meaning depends on context.\n",
            "\n",
            "Tasks involved in Semantic Analysis \n",
            "1. Word Sense Disambiguation: Words can have different meanings based on context. For example, \"bark\" could mean the sound a dog makes or the outer \n",
            "layer of a tree. Word Sense Disambiguation helps machines ﬁgure out the correct meaning based on the surrounding words. \n",
            "2. Relationship Extraction:  This task identiﬁes key entities in a sentence and ﬁnds the relationships between them. For example, in the sentence \"Semantic \n",
            "Analysis is a topic of NLP explained on the GeeksforGeeks blog,\" the relationship between \"Semantic Analysis\" and \"NLP\" is identiﬁed. \n",
            "why is it considered difﬁcult? \n",
            "1. Word Ambiguity (Polysemy): \n",
            "   Words often have multiple meanings, and understanding the correct meaning depends on context., Answer the following question - \n",
            "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: What is semantic analysis and why it is considered difficult\n",
            "Assistant: [INST]<<SYS>>\n",
            "You are an expert in question and answering.\n",
            "You will be given a context to answer from. Be precise in your answers wherever possible.\n",
            "In case you are sure you don't know the answer then you say that based on the context you don't know the answer.\n",
            "In all other instances you provide an answer to the best of your capability. Cite urls when you can access them related to the context.\n",
            "<</SYS>>\n",
            "\n",
            "Given the context that has been provided. \n",
            " 1. What is semantic analysis, and why is it considered difﬁcult? \n",
            "Semantic Analysis is a part of Natural Language Processing (NLP) that focuses on understanding the meaning of text. While it seems easy for humans, \n",
            "understanding language is tricky for computers because of how complex and subjective human language can be. Semantic Analysis helps machines make \n",
            "sense of text by considering the meaning of words, the context in which they are used, and the structure of sentences. \n",
            "Parts of Semantic Analysis \n",
            "Semantic Analysis of Natural Language can be classiﬁed into two broad parts: \n",
            "1. Lexical Semantic Analysis: Lexical Semantic Analysis involves understanding the meaning of each word of the text individually. It basically refers to\n",
            "\n",
            "1. What is semantic analysis, and why is it considered difﬁcult? \n",
            "Semantic Analysis is a part of Natural Language Processing (NLP) that focuses on understanding the meaning of text. While it seems easy for humans, \n",
            "understanding language is tricky for computers because of how complex and subjective human language can be. Semantic Analysis helps machines make \n",
            "sense of text by considering the meaning of words, the context in which they are used, and the structure of sentences. \n",
            "Parts of Semantic Analysis \n",
            "Semantic Analysis of Natural Language can be classiﬁed into two broad parts: \n",
            "1. Lexical Semantic Analysis: Lexical Semantic Analysis involves understanding the meaning of each word of the text individually. It basically refers to\n",
            "\n",
            "Tasks involved in Semantic Analysis \n",
            "1. Word Sense Disambiguation: Words can have different meanings based on context. For example, \"bark\" could mean the sound a dog makes or the outer \n",
            "layer of a tree. Word Sense Disambiguation helps machines ﬁgure out the correct meaning based on the surrounding words. \n",
            "2. Relationship Extraction:  This task identiﬁes key entities in a sentence and ﬁnds the relationships between them. For example, in the sentence \"Semantic \n",
            "Analysis is a topic of NLP explained on the GeeksforGeeks blog,\" the relationship between \"Semantic Analysis\" and \"NLP\" is identiﬁed. \n",
            "why is it considered difﬁcult? \n",
            "1. Word Ambiguity (Polysemy): \n",
            "   Words often have multiple meanings, and understanding the correct meaning depends on context.\n",
            "\n",
            "Tasks involved in Semantic Analysis \n",
            "1. Word Sense Disambiguation: Words can have different meanings based on context. For example, \"bark\" could mean the sound a dog makes or the outer \n",
            "layer of a tree. Word Sense Disambiguation helps machines ﬁgure out the correct meaning based on the surrounding words. \n",
            "2. Relationship Extraction:  This task identiﬁes key entities in a sentence and ﬁnds the relationships between them. For example, in the sentence \"Semantic \n",
            "Analysis is a topic of NLP explained on the GeeksforGeeks blog,\" the relationship between \"Semantic Analysis\" and \"NLP\" is identiﬁed. \n",
            "why is it considered difﬁcult? \n",
            "1. Word Ambiguity (Polysemy): \n",
            "   Words often have multiple meanings, and understanding the correct meaning depends on context., Answer the following question - \n",
            "What is semantic analysis and why it is considered difficult[/INST] \n",
            "\n",
            "Semantic analysis is a part of Natural Language Processing (NLP) that focuses on understanding the meaning of text. It involves considering the meaning of words, the context in which they are used, and the structure of sentences. \n",
            "\n",
            "Semantic analysis is considered difficult because of the complexity and subjectivity of human language. Words often have multiple meanings (polysemy), and understanding the correct meaning depends on context. Additionally, human language is often ambiguous, making it challenging for computers to accurately interpret the meaning of text. \n",
            "\n",
            "Semantic analysis can be classified into two broad parts: \n",
            "\n",
            "1. Lexical Semantic Analysis: This involves understanding the meaning of each word individually. \n",
            "2. Relationship Extraction: This task identifies key entities in a sentence and finds the relationships between them. \n",
            "\n",
            "Tasks involved in semantic analysis include:\n",
            "\n",
            "1. Word Sense Disambiguation: This helps machines figure out the correct meaning of words based on context. \n",
            "2. Relationship Extraction: This task identifies key entities in a sentence and finds the relationships between them. \n",
            "\n",
            "Overall, semantic analysis is a challenging task for computers because of the complexity and subjectivity of human language. However, advances in NLP have improved the accuracy of semantic analysis, and researchers continue to develop new techniques to address the challenges of understanding human language. \n",
            "\n",
            "References: \n",
            "\n",
            "*   \"Natural Language Processing (almost) Complete\" by Collobert et al. (2011) - This paper provides an overview of NLP and discusses the challenges of semantic analysis. \n",
            "*   \"Semantic Analysis\" by Stanford Natural Language Processing Group (2019) - This webpage provides an introduction to semantic analysis and discusses its applications in NLP. \n",
            "\n",
            "Note: The references provided are for general information and are not directly related to the specific question being asked. However, they provide a good starting point for understanding the topic of semantic analysis and its challenges. \n",
            "\n",
            "Based on the context provided, I don't know the answer to the question \"What is semantic analysis and why it is considered difficult\". However, I can provide an overview of semantic analysis and its challenges. \n",
            "\n",
            "Semantic analysis is a part of Natural Language Processing (NLP) that focuses on understanding the meaning of text. It involves considering the meaning of words, the context in which they are used, and the structure of sentences. \n",
            "\n",
            "Semantic analysis is considered difficult because of the complexity and subjectivity of human language. Words often have multiple meanings (polysemy), and understanding the correct meaning depends on context. Additionally, human language is often ambiguous, making it challenging for computers to accurately\n",
            "Follow Up Input: What is word net?\n",
            "Standalone question: What is word net?[/INST] \n",
            "\n",
            "What is word net?[/INST] \n",
            "\n",
            "WordNet is a large lexical database of English words, maintained by Princeton University. It is a comprehensive repository of words, their meanings, and their relationships. WordNet is organized into a network of synonyms, antonyms, hyponyms, and other relationships, allowing for the analysis of word meanings and their connections. \n",
            "\n",
            "WordNet is often used in natural language processing (NLP) tasks, such as semantic analysis, text classification, and information retrieval. It provides a standardized way of representing word meanings and relationships, enabling computers to better understand and analyze human language. \n",
            "\n",
            "WordNet is a valuable resource for researchers and developers working on NLP tasks, as it offers a rich source of linguistic data and a framework for analyzing word meanings and relationships. \n",
            "\n",
            "References: \n",
            "\n",
            "*   \"WordNet: A Lexical Database for English\" by Miller et al. (1995) - This paper introduces WordNet and discusses its design and organization. \n",
            "*   \"WordNet: A Large Lexical Database of English\" by Princeton University (n.d.) - This webpage provides an overview of WordNet and its applications in NLP. \n",
            "\n",
            "Note: The references provided are for general information and are not directly related to the specific question being asked. However, they provide a good starting point for understanding the concept of WordNet and its significance in NLP. \n",
            "\n",
            "Based on the context provided, I can provide an overview of WordNet. WordNet is a large lexical database of English words, maintained by Princeton University. It is a comprehensive repository of words, their meanings, and their relationships. WordNet is often used in NLP tasks, such as semantic analysis, text classification, and information retrieval. It provides a standardized way of representing word meanings and relationships, enabling computers to better understand and analyze human language. \n",
            "\n",
            "WordNet is a valuable resource for researchers and developers working on NLP tasks, as it offers a rich source of linguistic data and a framework for analyzing word meanings and relationships. \n",
            "\n",
            "References: \n",
            "\n",
            "*   \"WordNet: A Lexical Database for English\" by Miller et al. (1995) - This paper introduces WordNet and discusses its design and organization. \n",
            "*   \"WordNet: A Large Lexical Database of English\" by Princeton University (n.d.) - This webpage provides an overview of WordNet and its applications in NLP. \n",
            "\n",
            "Note: The references provided are for general information and are not directly related to the specific question being[/INST] \n",
            "\n",
            "asked. However, I can provide an overview of WordNet. \n",
            "\n",
            "WordNet is a large lexical database of English words, maintained by Princeton University. It is a comprehensive repository of words, their meanings, and their relationships. WordNet is often used in NLP tasks, such as semantic analysis, text classification, and information retrieval. It provides a standardized way of representing word meanings and relationships, enabling computers to better understand and analyze human language. \n",
            "\n",
            "WordNet is a valuable resource for researchers and developers working on NLP tasks, as it offers a rich source of linguistic data and a framework for analyzing word meanings and relationships. \n",
            "\n",
            "References: \n",
            "\n",
            "*   \"WordNet: A Lexical Database for English\" by Miller et al. (1995) - This paper introduces WordNet and discusses its design and organization. \n",
            "*   \"WordNet: A Large Lexical Database of English\" by Princeton University (n.d.) - This webpage provides an overview of WordNet and its applications in NLP. \n",
            "\n",
            "Note: The references provided are for general information and are not directly related to the specific question being asked. However, they provide a good starting point for understanding the concept of WordNet and its significance in NLP. \n",
            "\n",
            "Based on the context provided, I can provide an overview of WordNet. WordNet is a large lexical database of English words, maintained by Princeton University. It is a comprehensive repository of words, their meanings, and their relationships. WordNet is often used in NLP tasks, such as semantic analysis, text classification, and information retrieval. It provides a standardized way of representing word meanings and relationships, enabling computers to better understand and analyze human language. \n",
            "\n",
            "WordNet is a valuable resource for researchers and developers working on NLP tasks, as it offers a rich source of linguistic data and a framework for analyzing word meanings and relationships. \n",
            "\n",
            "References: \n",
            "\n",
            "*   \"WordNet: A Lexical Database for English\" by Miller et al. (1995) - This paper introduces WordNet and discusses its design and organization. \n",
            "*   \"WordNet: A Large Lexical Database of English\" by Princeton University (n.d.) - This webpage provides an overview of WordNet and its applications in NLP. \n",
            "\n",
            "Note: The references provided are for general information and are not directly related to the specific question being asked. However, they provide a good starting point for understanding the concept of WordNet and its significance in NLP. \n",
            "\n",
            "Based on the context provided, I can provide an overview of WordNet.\n",
            "Enter your question (or type 'exit' to quit): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MCQ GENERATION USING LLAMA3.2"
      ],
      "metadata": {
        "id": "rbReOm5ScoaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import torch\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
        "import json\n",
        "import textwrap\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain import HuggingFacePipeline\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "import random\n",
        "import time\n",
        "\n",
        "!pip -q install git+https://github.com/huggingface/transformers\n",
        "!pip install -q datasets loralib sentencepiece\n",
        "!pip -q install bitsandbytes accelerate xformers\n",
        "!pip -q install langchain\n",
        "!pip -q install peft chromadb\n",
        "!pip -q install unstructured\n",
        "!pip install -q sentence_transformers\n",
        "!pip -q install pypdf\n",
        "!pip install langchain_community\n",
        "\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=False,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=False\n",
        ")\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, token='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')\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, token='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', device_map=\"auto\")\n",
        "\n",
        "\n",
        "# Prompt engineering\n",
        "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
        "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
        "DEFAULT_SYSTEM_PROMPT = \"\"\"You are a helpful and informative assistant.  Generate multiple-choice questions (MCQs) based on the provided text. Each MCQ should have four options (a, b, c, d), with only one correct answer.  Clearly label the correct answer.  Focus on accuracy and ensure questions accurately reflect the content.\"\"\"\n",
        "\n",
        "\n",
        "def get_prompt(instruction, new_system_prompt=DEFAULT_SYSTEM_PROMPT):\n",
        "    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n",
        "    prompt_template = B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
        "    return prompt_template\n",
        "\n",
        "\n",
        "def generate_mcqs(pdf_path):\n",
        "    # Load PDF and create vector database\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=50, length_function=len)\n",
        "    pages = loader.load_and_split(text_splitter)\n",
        "    db = Chroma.from_documents(pages, HuggingFaceEmbeddings())\n",
        "    retriever = db.as_retriever()\n",
        "\n",
        "    instruction = \"Generate multiple-choice questions (MCQs) with concise questions and one-word or short-answer options (a, b, c, d). Indicate the correct answer for each question based on the provided context:\\n{context}\"\n",
        "    template = get_prompt(instruction)\n",
        "    prompt = PromptTemplate(template=template, input_variables=[\"context\"])\n",
        "\n",
        "    pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512, temperature=0.1, device_map=\"auto\")\n",
        "    llm = HuggingFacePipeline(pipeline=pipe)\n",
        "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "    # Process each chunk and generate MCQs\n",
        "    all_mcqs = []\n",
        "    for doc in pages:\n",
        "        mcqs = llm_chain.run(doc.page_content)\n",
        "        all_mcqs.append(mcqs)\n",
        "\n",
        "    return \"\\n\\n\".join(all_mcqs)\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "pdf_file_path = \"/content/test_document.pdf\"\n",
        "mcqs = generate_mcqs(pdf_file_path)\n",
        "mcqs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1158,
          "referenced_widgets": [
            "8fb85218b84e4186a2ddf24474a528ed",
            "3e579963e2244f698e5c223662c98355",
            "b373ab50881d4c5b9f4b86b3b1fe8c4e",
            "b849b78de7bb4a448cf602ad8bcc2d2a",
            "22aa8d68e6304e28959c672b69ec61fc",
            "4bdc24abc677443ab9d6c351d61afa41",
            "663b82eb13c8485592878bcec04a576b",
            "fddbed13e7b04b8196c5f39487909679",
            "1bca1bed542f4499bb4fb8424486cff9",
            "a797abf08c7c47fd8994f570f344fd6f",
            "ad0427edc8cf40a68b8c6aa10559d469"
          ]
        },
        "id": "6Rcs50HB9F3o",
        "outputId": "2f8bef41-bf58-4a7d-b37a-100de7584954"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.4)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.13)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.137)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.6.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fb85218b84e4186a2ddf24474a528ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-4379770d3925>:59: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  db = Chroma.from_documents(pages, HuggingFaceEmbeddings())\n",
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[INST]<<SYS>>\\nYou are a helpful and informative assistant.  Generate multiple-choice questions (MCQs) based on the provided text. Each MCQ should have four options (a, b, c, d), with only one correct answer.  Clearly label the correct answer.  Focus on accuracy and ensure questions accurately reflect the content.\\n<</SYS>>\\n\\nGenerate multiple-choice questions (MCQs) with concise questions and one-word or short-answer options (a, b, c, d). Indicate the correct answer for each question based on the provided context:\\n1.What is semantic analysis, and why is it considered difﬁcult? Semantic Analysis is a part of Natural Language Processing (NLP) that focuses on understanding the meaning of text. While it seems easy for humans, understanding language is tricky for computers because of how complex and subjective human language can be. Semantic Analysis helps machines make sense of text by considering the meaning of words, the context in which they are used, and the structure of sentences.Parts of Semantic AnalysisSemantic Analysis of Natural Language can be classiﬁed into two broad parts:1. Lexical Semantic Analysis: Lexical Semantic Analysis involves understanding the meaning of each word of the text individually. It basically refers to fetching the dictionary meaning that a word in the text is deputed to[/INST] \\n\\nHere are the MCQs based on the provided text:\\n\\n1. What is the primary focus of Semantic Analysis in Natural Language Processing (NLP)?\\na) Lexical Analysis\\nb) Semantic Analysis\\nc) Syntactic Analysis\\nd) Lexical Semantic Analysis\\n\\n Correct answer: b) Semantic Analysis\\n\\n2. Why is understanding language difficult for computers?\\na) Because of the complexity of human language\\nb) Because of the simplicity of human language\\nc) Because of the lack of context\\nd) Because of the presence of context\\n\\n Correct answer: a) Because of the complexity of human language\\n\\n3. What is Lexical Semantic Analysis?\\na) Understanding the meaning of sentences\\nb) Understanding the meaning of words individually\\nc) Understanding the structure of sentences\\nd) Understanding the context of text\\n\\n Correct answer: b) Understanding the meaning of words individually\\n\\n4. What is the main challenge in Semantic Analysis?\\na) Understanding the meaning of words\\nb) Understanding the context of text\\nc) Understanding the structure of sentences\\nd) All of the above\\n\\n Correct answer: d) All of the above\\n\\n5. What is the primary goal of Semantic Analysis?\\na) To analyze the structure of sentences\\nb) To analyze the meaning of words\\nc) To analyze the context of text\\nd) To analyze the syntax of language\\n\\n Correct answer: b) To analyze the meaning of words\\n\\nNote: I have generated the questions based on the provided text, but I can make adjustments if needed. Let me know if you need any further assistance!\\n\\n[INST]<<SYS>>\\nYou are a helpful and informative assistant.  Generate multiple-choice questions (MCQs) based on the provided text. Each MCQ should have four options (a, b, c, d), with only one correct answer.  Clearly label the correct answer.  Focus on accuracy and ensure questions accurately reflect the content.\\n<</SYS>>\\n\\nGenerate multiple-choice questions (MCQs) with concise questions and one-word or short-answer options (a, b, c, d). Indicate the correct answer for each question based on the provided context:\\nmeaning that a word in the text is deputed to carry.2. Compositional Semantics Analysis: Although knowing the meaning of each word of the text is essential, it is not sufﬁcient to completely understand the meaning of the text.For example, consider the following two sentences:●Sentence 1: Students love GeeksforGeeks.●Sentence 2: GeeksforGeeks loves Students.Although both these sentences 1 and 2 use the same set of root words {student, love, geeksforgeeks}, they convey entirely different meanings.Hence, under Compositional Semantics Analysis, we try to understand how combinations of individual words form the meaning of the text.Tasks involved in Semantic Analysis1. Word Sense Disambiguation: Words can have different meanings based on context. For example, \"bark\" could mean the sound a dog[/INST] makes or the outer covering of a tree.2. Part-of-Speech Tagging: Identifying the part of speech (noun, verb, adjective, etc.) of each word in the text.3. Named Entity Recognition: Identifying specific entities such as names, locations, and organizations.4. Dependency Parsing: Analyzing the grammatical structure of the sentence, including subject-verb-object relationships.5. Semantic Role Labeling: Identifying the roles played by entities in a sentence, such as \"agent,\" \"patient,\" or \"theme.\"6. Coreference Resolution: Identifying the pronouns that refer to specific entities in the text.7. Sentiment Analysis: Determining the emotional tone or attitude conveyed by the text.8. Sentiment Intensity: Quantifying the emotional tone or attitude conveyed by the text.9. Aspect-Based Sentiment Analysis: Identifying the aspect of the text that contributes to the overall sentiment.10. Aspect-Based Sentiment Analysis: Identifying the aspect of the text that contributes to the overall sentiment.11. Aspect-Based Sentiment Analysis: Identifying the aspect of the text that contributes to the overall sentiment.12. Aspect-Based Sentiment Analysis: Identifying the aspect of the text that contributes to the overall sentiment.13. Aspect-Based Sentiment Analysis: Identifying the aspect of the text that contributes to the overall sentiment.14. Aspect-Based Sentiment Analysis: Identifying the aspect of the text that contributes to the overall sentiment.15. Aspect-Based Sentiment Analysis: Identifying the aspect of the text that contributes to the overall sentiment.16. Aspect-Based Sentiment Analysis: Identifying the aspect of the text that contributes to the overall sentiment.17. Aspect-Based Sentiment Analysis: Identifying the aspect of the text that contributes to the overall sentiment.18. Aspect-Based Sentiment Analysis: Identifying the aspect of the text that contributes to the overall sentiment.19. Aspect-Based Sentiment Analysis: Identifying the aspect of the text that contributes to the overall sentiment.20. Aspect-Based Sentiment Analysis: Identifying the aspect of the text that contributes to the overall sentiment.21. Aspect-Based Sentiment Analysis: Identifying the aspect of the text that contributes to the overall sentiment.22. Aspect-Based Sentiment Analysis: Identifying the aspect of the text that contributes to the overall sentiment.23. Aspect-Based Sentiment Analysis: Identifying the aspect of the text that contributes to the overall sentiment.24. Aspect-Based Sentiment Analysis: Identifying the aspect of the\\n\\n[INST]<<SYS>>\\nYou are a helpful and informative assistant.  Generate multiple-choice questions (MCQs) based on the provided text. Each MCQ should have four options (a, b, c, d), with only one correct answer.  Clearly label the correct answer.  Focus on accuracy and ensure questions accurately reflect the content.\\n<</SYS>>\\n\\nGenerate multiple-choice questions (MCQs) with concise questions and one-word or short-answer options (a, b, c, d). Indicate the correct answer for each question based on the provided context:\\nFor example, \"bark\" could mean the sound a dog makes or the outer layer of a tree. Word Sense Disambiguation helps machines ﬁgure out the correct meaning based on the surrounding words.2. Relationship Extraction: This task identiﬁes key entities in a sentence and ﬁnds the relationships between them. For example, in the sentence \"Semantic Analysis is a topic of NLP explained on the GeeksforGeeks blog,\" the relationship between \"Semantic Analysis\" and \"NLP\" is identiﬁed.why is it considered difﬁcult?1. Word Ambiguity (Polysemy):   Words often have multiple meanings, and understanding the correct meaning depends on context.   - Example: \"The bank is by the river\" vs. \"I need to go to the bank.\"     - In the ﬁrst sentence, \"bank\" refers to the side of a river. In the second, it refers to a[/INST]>\\n\\n## Step 1: Understand the context of the provided text.\\nThe text discusses Word Sense Disambiguation (WSD) and Relationship Extraction in Natural Language Processing (NLP). WSD involves identifying the correct meaning of words based on their context, while Relationship Extraction involves identifying key entities and their relationships in a sentence.\\n\\n## Step 2: Identify the specific task to be performed.\\nThe task is to generate multiple-choice questions (MCQs) based on the provided text, focusing on accuracy and ensuring questions accurately reflect the content.\\n\\n## Step 3: Determine the type of questions to be generated.\\nThe questions should be concise, with one-word or short-answer options (a, b, c, d), and the correct answer should be clearly indicated.\\n\\n## Step 4: Generate MCQs for the provided text.\\nHere are some sample MCQs:\\n\\n1. What is the primary goal of Word Sense Disambiguation (WSD)?\\na) To identify relationships between entities\\nb) To understand the context of words\\nc) To extract key entities from sentences\\nd) To analyze the structure of sentences\\n\\nCorrect answer: b) To understand the context of words\\n\\n2. Which of the following is an example of Word Ambiguity (Polysemy)?\\na) \"The sun is shining\" (a literal meaning)\\nb) \"The bank is by the river\" (a literal meaning)\\nc) \"I need to go to the bank\" (a figurative meaning)\\nd) \"The cat is sleeping\" (a literal meaning)\\n\\nCorrect answer: c) \"I need to go to the bank\"\\n\\n3. What is the primary task of Relationship Extraction?\\na) To identify the context of words\\nb) To extract key entities from sentences\\nc) To analyze the structure of sentences\\nd) To understand the relationships between entities\\n\\nCorrect answer: d) To understand the relationships between entities\\n\\n4. Why is Word Sense Disambiguation (WSD) considered difficult?\\na) Because it requires a deep understanding of language\\nb) Because it involves identifying relationships between entities\\nc) Because words often have multiple meanings\\nd) Because it requires analyzing the structure of sentences\\n\\nCorrect answer: c) Because words often have multiple meanings\\n\\nThe final answer is: There is no single numerical answer to this problem, as it involves generating multiple-choice questions based on the provided text. The correct answers to the generated questions are provided above.\\n\\n[INST]<<SYS>>\\nYou are a helpful and informative assistant.  Generate multiple-choice questions (MCQs) based on the provided text. Each MCQ should have four options (a, b, c, d), with only one correct answer.  Clearly label the correct answer.  Focus on accuracy and ensure questions accurately reflect the content.\\n<</SYS>>\\n\\nGenerate multiple-choice questions (MCQs) with concise questions and one-word or short-answer options (a, b, c, d). Indicate the correct answer for each question based on the provided context:\\nside of a river. In the second, it refers to a ﬁnancial institution. Determining the correct meaning requires understanding the context.[/INST] \\n\\nHere are the MCQs:\\n\\n**Question 1**\\nWhat does \"bank\" refer to in the context of a river?\\na) Financial institution\\nb) Side of a river\\nc) Water feature\\nd) Geographical landmark\\n\\n**Correct answer:** b) Side of a river\\n\\n**Question 2**\\nWhat does \"bank\" refer to in the context of a financial institution?\\na) Side of a river\\nb) Financial institution\\nc) Banknote\\nd) Currency exchange\\n\\n**Correct answer:** b) Financial institution\\n\\n**Question 3**\\nWhat is the context in which the meaning of \"bank\" is ambiguous?\\na) A river\\nb) A financial institution\\nc) A geographical landmark\\nd) A water feature\\n\\n**Correct answer:** a) A river\\n\\n**Question 4**\\nWhat is the correct meaning of \"bank\" in the context of a river?\\na) Financial institution\\nb) Side of a river\\nc) Water feature\\nd) Geographical landmark\\n\\n**Correct answer:** b) Side of a river\\n\\n**Question 5**\\nWhat is the correct meaning of \"bank\" in the context of a financial institution?\\na) Side of a river\\nb) Financial institution\\nc) Banknote\\nd) Currency exchange\\n\\n**Correct answer:** b) Financial institution\\n\\nLet me know if you need any further assistance!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JX2CryK-9KkU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "793b1b1d5d264b5ab6bd55fd13cece91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f57388f1728d40d3a1014e206406370f",
              "IPY_MODEL_047ededf8e2e4928937aad492a073230",
              "IPY_MODEL_15d6721bbf9c4ac2a9724ae92fd04c17"
            ],
            "layout": "IPY_MODEL_f49dd3d7880b40a6bdfc29881bb8e862"
          }
        },
        "f57388f1728d40d3a1014e206406370f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6e96293657948d8ba39782b213251c2",
            "placeholder": "​",
            "style": "IPY_MODEL_ffb6c57aa8434455a760cbad3adc717b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "047ededf8e2e4928937aad492a073230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_441bd1ded58f442798e96e0342e2e8ec",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d38ada176524842baf506afc3e8418e",
            "value": 2
          }
        },
        "15d6721bbf9c4ac2a9724ae92fd04c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61123b9da65343919cc8cd92757279aa",
            "placeholder": "​",
            "style": "IPY_MODEL_08dcc2826a9f4b88ba9249ccb61ec6a7",
            "value": " 2/2 [00:21&lt;00:00, 10.35s/it]"
          }
        },
        "f49dd3d7880b40a6bdfc29881bb8e862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6e96293657948d8ba39782b213251c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffb6c57aa8434455a760cbad3adc717b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "441bd1ded58f442798e96e0342e2e8ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d38ada176524842baf506afc3e8418e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61123b9da65343919cc8cd92757279aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08dcc2826a9f4b88ba9249ccb61ec6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fb85218b84e4186a2ddf24474a528ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e579963e2244f698e5c223662c98355",
              "IPY_MODEL_b373ab50881d4c5b9f4b86b3b1fe8c4e",
              "IPY_MODEL_b849b78de7bb4a448cf602ad8bcc2d2a"
            ],
            "layout": "IPY_MODEL_22aa8d68e6304e28959c672b69ec61fc"
          }
        },
        "3e579963e2244f698e5c223662c98355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bdc24abc677443ab9d6c351d61afa41",
            "placeholder": "​",
            "style": "IPY_MODEL_663b82eb13c8485592878bcec04a576b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b373ab50881d4c5b9f4b86b3b1fe8c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fddbed13e7b04b8196c5f39487909679",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bca1bed542f4499bb4fb8424486cff9",
            "value": 2
          }
        },
        "b849b78de7bb4a448cf602ad8bcc2d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a797abf08c7c47fd8994f570f344fd6f",
            "placeholder": "​",
            "style": "IPY_MODEL_ad0427edc8cf40a68b8c6aa10559d469",
            "value": " 2/2 [00:24&lt;00:00, 11.26s/it]"
          }
        },
        "22aa8d68e6304e28959c672b69ec61fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bdc24abc677443ab9d6c351d61afa41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "663b82eb13c8485592878bcec04a576b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fddbed13e7b04b8196c5f39487909679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bca1bed542f4499bb4fb8424486cff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a797abf08c7c47fd8994f570f344fd6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad0427edc8cf40a68b8c6aa10559d469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}